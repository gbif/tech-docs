= Data publishing

Most institutions publishing data to GBIF need to convert their data into a format suitable for GBIF to process, typically Darwin Core Archive.

Tools including the https://ipt.gbif.org/manual/[GBIF IPT] and BioCASe can convert data stored in spreadsheets and databases to the appropriate formats.  *The IPT is the most common way to publish data to GBIF.*

Some institutional collections management systems, such as Symbiota or EarthCape, can export all or part of their data to GBIF.

Users or institutional systems (custom software) which can generate Darwin Core Archives and make them available on a webserver have two options:

* For occasional datasets (one or two per year) contact the mailto:helpdesk@gbif.org[GBIF helpdesk], who will register the dataset on your behalf.
* If new datasets will be registered more frequently, you may xref:register-dataset-api.adoc[register the datasets directly using the API].

Further discussion of the options can be found in https://data-blog.gbif.org/post/installations-and-hosting-solutions-explained/[this blogpost]

//== Dataset classes

//Dataset can be published in four different formats:

//* Metadata-only
//* Checklist
//* Occurrence
//* Sampling event

//Generally, the data quality increases from metadata-only to sampling event datasets.

//== Data quality recommendations

//You can familiarize yourself with the requirements for the various types of dataset https://www.gbif.org/data-quality-requirements[here]

== Tools to quality check your publication

=== Dataset validator

The dataset validator can be used to https://www.gbif.org/tools/data-validator/about[validate] zipped Darwin Core Archive datasets.

//== Species matching

//== Species API (link to API topic)

//== The test IPT

//== The meaning of flags and issues and how you should deal with them

//== Data publishing FAQ

//* change occurrence IDs
//* citations

//== Other

//(Moved here from the main menu.)

//* DNA derived data
